# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZpOjbD7Ng6qF05J6WWtKTcTNVG6CguC5
"""

from google.colab import drive
drive.mount('/content/drive')

# importing libraries
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn import preprocessing
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import VotingClassifier
from keras.layers import Dropout
from keras import callbacks
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import  mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout


def part2():
    # Loading the dataset
    dataset = pd.read_csv(r"/content/drive/MyDrive/project/data/prices.csv")

    # the dataset has no null values
    dataset = dataset[dataset['symbol'] == 'AAPL']

    # plotting the stock price for apple from 2010 to 2016
    stockprice = plt.figure()
    axis = sb.lineplot(data=dataset, x='date', y='open')
    plt.title('Apple stock prices 2010-2016')

    # removing the columns which are not correlated to 'close'

    dataset = dataset.drop(['symbol', 'volume', 'date'], axis=1)
    X = dataset.drop(['close'], axis=1)
    y = dataset['close']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    accuracy = []
    # linear regression model with default parameters
    linreg = LinearRegression()
    linreg.fit(X_train, y_train)
    y_pred1 = linreg.predict(X_test)

    # using r2 score for accuracy predictions
    print("Accuracy for Linear Regression: {0}".format(r2_score(y_test, y_pred1)))
    accuracy.append(r2_score(y_test, y_pred1))
    mse = mean_squared_error(y_test, y_pred1)
    print(mse)

    # Dividing values between training and test and then scaling the values
    train = X.iloc[:1000].values
    test = X.iloc[1000:].values

    scalar = MinMaxScaler(feature_range=(0, 1))
    train_scaled = scalar.fit_transform(train)
    test_scaled = scalar.transform(test)

    # Creating time steps for LSTM execution
    # Reference - https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/
    length = 100
    # For xtrain and ytrain
    X_train = []
    y_train = []
    for i in range(length, len(train)):
        X_train.append(train_scaled[i - length:i, 0])
        y_train.append(train_scaled[i, 0])
    X_train, y_train = np.array(X_train), np.array(y_train)
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

    # for xtest and ytest
    X_test = []
    y_test = []
    for i in range(length, len(test)):
        X_test.append(test_scaled[i - length:i, 0])
        y_test.append(test_scaled[i, 0])
    X_test, y_test = np.array(X_test), np.array(y_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

    # Creating a LSTM model
    model = Sequential()
    # using return sequences = true
    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))

    model.add(LSTM(units=50, return_sequences=True))

    model.add(LSTM(units=50, return_sequences=True))
    # using dropout layer for better performance
    model.add(Dropout(0.25))

    model.add(LSTM(units=50))

    model.add(Dense(units=1))

    # Compiling
    model.compile(optimizer='adam', loss='mean_squared_error')

    # fitting
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)

    print(history.history.keys())

    loss = pd.DataFrame(model.history.history)
    fig = plt.figure(figsize=(15, 8))
    plt.title("Validation Loss vs Number of Epochs", size=20, weight='bold')
    plt.plot(loss)


if __name__ == "__main__":
    #part1()
    part2()

